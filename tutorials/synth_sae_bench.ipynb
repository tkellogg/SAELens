{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# SynthSAEBench: Evaluating SAE Architectures on Synthetic Data\n",
    "\n",
    "This tutorial walks through using SynthSAEBench to train and evaluate SAE architectures on large-scale synthetic data with known ground-truth features.\n",
    "\n",
    "SynthSAEBench provides:\n",
    "\n",
    "- A pretrained synthetic model (**SynthSAEBench-16k**) with 16,384 ground-truth features exhibiting realistic properties: Zipfian firing distributions, hierarchical features, correlated firings, and superposition\n",
    "- A training runner (**SyntheticSAERunner**) for training SAEs at scale with wandb logging and periodic evaluation\n",
    "- Ground-truth evaluation metrics (MCC, F1, precision, recall) that measure how well an SAE recovers the true underlying features\n",
    "\n",
    "Unlike LLM benchmarks where the ground truth is unknown, SynthSAEBench lets you precisely diagnose *why* an SAE architecture succeeds or fails.\n",
    "\n",
    "For background on the synthetic data primitives (FeatureDictionary, ActivationGenerator, etc.), see the [training on synthetic data tutorial](https://github.com/decoderesearch/SAELens/blob/main/tutorials/training_saes_on_synthetic_data.ipynb). This tutorial focuses on the large-scale benchmark workflow.\n",
    "\n",
    "**NOTE:** This notebook requires a GPU to run in a reasonable time. Training on SynthSAEBench-16k takes ~15-20 minutes per SAE on an H100 but will be extremely slow on CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "\n",
    "    COLAB = True\n",
    "    %pip install sae-lens\n",
    "except Exception:\n",
    "    COLAB = False\n",
    "\n",
    "device = \"cuda\"\n",
    "if not torch.cuda.is_available():\n",
    "    warnings.warn(\n",
    "        \"CUDA is not available. This notebook requires a GPU to run in a reasonable time. \"\n",
    "        \"Training on SynthSAEBench-16k takes ~15-20 minutes on an H100 but will be \"\n",
    "        \"extremely slow on CPU.\",\n",
    "        stacklevel=1,\n",
    "    )\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-model-header",
   "metadata": {},
   "source": [
    "## Loading the SynthSAEBench-16k Model\n",
    "\n",
    "The SynthSAEBench-16k model is the standard benchmark. It has 16,384 ground-truth features in a 768-dimensional hidden space, with Zipfian firing probabilities, hierarchical structure, low-rank correlations, and superposition.\n",
    "\n",
    "Let's load it and explore its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.synthetic import SyntheticModel\n",
    "\n",
    "model = SyntheticModel.from_pretrained(\n",
    "    \"decoderesearch/synth-sae-bench-16k-v1\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"Number of ground-truth features: {model.cfg.num_features:,}\")\n",
    "print(f\"Hidden dimension: {model.cfg.hidden_dim}\")\n",
    "print(f\"Superposition ratio: {model.cfg.num_features / model.cfg.hidden_dim:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-header",
   "metadata": {},
   "source": [
    "### Exploring the model\n",
    "\n",
    "We can sample activations and inspect their statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample hidden activations and ground-truth feature activations\n",
    "hidden_acts, feature_acts = model.sample_with_features(batch_size=10_000)\n",
    "\n",
    "print(f\"Hidden activations shape: {hidden_acts.shape}\")\n",
    "print(f\"Feature activations shape: {feature_acts.shape}\")\n",
    "print(\n",
    "    f\"Hidden activation L2 norm: {hidden_acts.norm(dim=1).mean():.1f}\"\n",
    "    f\" (std: {hidden_acts.norm(dim=1).std():.1f})\"\n",
    ")\n",
    "\n",
    "# L0: average number of active features per sample\n",
    "l0 = (feature_acts > 0).float().sum(dim=1).mean()\n",
    "print(f\"Average L0 (active features per sample): {l0:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "firing-dist-header",
   "metadata": {},
   "source": [
    "### Firing probability distribution\n",
    "\n",
    "The model uses Zipfian firing probabilities, where a few features fire frequently and most fire rarely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "firing-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Estimate firing frequencies from samples\n",
    "firing_freqs = (feature_acts > 0).float().mean(dim=0).cpu()\n",
    "\n",
    "fig = px.histogram(\n",
    "    x=firing_freqs.numpy(),\n",
    "    nbins=50,\n",
    "    log_y=True,\n",
    "    title=\"Feature firing frequency distribution (SynthSAEBench-16k)\",\n",
    "    labels={\"x\": \"Firing frequency\", \"y\": \"Feature count\"},\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## Training a BatchTopK SAE\n",
    "\n",
    "Now let's train a BatchTopK SAE on SynthSAEBench-16k using the `SyntheticSAERunner`. We recommend:\n",
    "\n",
    "- **Width 4096**: In practice, SAEs are narrower than the true number of features\n",
    "- **200M training samples** with batch size 1024 and LR 3e-4\n",
    "- **k=25**: A reasonable sparsity target for this model\n",
    "\n",
    "Training takes about 15-20 minutes on an H100 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-batchtopk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.synthetic import SyntheticSAERunner, SyntheticSAERunnerConfig\n",
    "from sae_lens import BatchTopKTrainingSAEConfig, LoggingConfig\n",
    "\n",
    "runner_cfg = SyntheticSAERunnerConfig(\n",
    "    synthetic_model=\"decoderesearch/synth-sae-bench-16k-v1\",\n",
    "    sae=BatchTopKTrainingSAEConfig(\n",
    "        d_in=768,\n",
    "        d_sae=4096,\n",
    "        k=25,\n",
    "    ),\n",
    "    training_samples=200_000_000,\n",
    "    batch_size=1024,\n",
    "    lr=3e-4,\n",
    "    eval_frequency=1000,\n",
    "    eval_samples=500_000,\n",
    "    autocast_sae=True,\n",
    "    autocast_data=True,\n",
    "    logger=LoggingConfig(log_to_wandb=False),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "runner = SyntheticSAERunner(runner_cfg)\n",
    "btk_result = runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## Evaluating the trained SAE\n",
    "\n",
    "The runner automatically runs a final evaluation against the ground-truth features. Let's look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = btk_result.final_eval\n",
    "assert eval_result is not None\n",
    "\n",
    "print(\"BatchTopK SAE Results:\")\n",
    "print(f\"  Explained variance (R\\u00b2): {eval_result.explained_variance:.4f}\")\n",
    "print(f\"  MCC:                     {eval_result.mcc:.4f}\")\n",
    "print(f\"  Uniqueness:              {eval_result.uniqueness:.4f}\")\n",
    "print(f\"  F1:                      {eval_result.classification.f1_score:.4f}\")\n",
    "print(f\"  Precision:               {eval_result.classification.precision:.4f}\")\n",
    "print(f\"  Recall:                  {eval_result.classification.recall:.4f}\")\n",
    "print(f\"  SAE L0:                  {eval_result.sae_l0:.1f}\")\n",
    "print(f\"  True L0:                 {eval_result.true_l0:.1f}\")\n",
    "print(f\"  Dead latents:            {eval_result.dead_latents}\")\n",
    "print(f\"  Shrinkage:               {eval_result.shrinkage:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics-header",
   "metadata": {},
   "source": [
    "### Understanding the metrics\n",
    "\n",
    "- **Explained variance (R²)**: How well the SAE reconstructs inputs. 1.0 = perfect reconstruction.\n",
    "- **MCC**: Mean Correlation Coefficient — measures alignment between SAE decoder columns and ground-truth feature vectors via optimal bipartite matching. 1.0 = perfect feature recovery.\n",
    "- **Uniqueness**: Fraction of SAE latents that map to distinct ground-truth features. Low uniqueness means multiple latents represent the same feature.\n",
    "- **F1 / Precision / Recall**: Each SAE latent is treated as a binary classifier for its best-matching ground-truth feature. Precision measures false positive rate; recall measures false negative rate.\n",
    "- **L0**: Average active latents per sample. Compare SAE L0 to true L0.\n",
    "- **Dead latents**: Latents that never activate — wasted capacity.\n",
    "- **Shrinkage**: Ratio of output to input norm. Values below 1.0 mean the SAE systematically reduces activation magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## Comparing SAE Architectures\n",
    "\n",
    "One of the key uses of SynthSAEBench is comparing different SAE architectures. Let's train a Matryoshka BatchTopK SAE and a Standard L1 SAE for comparison.\n",
    "\n",
    "### Matryoshka BatchTopK SAE\n",
    "\n",
    "Matryoshka SAEs use nested reconstruction losses at multiple widths to encourage better latent quality and reduce feature absorption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-matryoshka",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import MatryoshkaBatchTopKTrainingSAEConfig\n",
    "\n",
    "matryoshka_cfg = SyntheticSAERunnerConfig(\n",
    "    synthetic_model=\"decoderesearch/synth-sae-bench-16k-v1\",\n",
    "    sae=MatryoshkaBatchTopKTrainingSAEConfig(\n",
    "        d_in=768,\n",
    "        d_sae=4096,\n",
    "        k=25,\n",
    "        matryoshka_widths=[128, 512, 2048],\n",
    "    ),\n",
    "    training_samples=200_000_000,\n",
    "    batch_size=1024,\n",
    "    lr=3e-4,\n",
    "    eval_frequency=1000,\n",
    "    eval_samples=500_000,\n",
    "    autocast_sae=True,\n",
    "    autocast_data=True,\n",
    "    logger=LoggingConfig(log_to_wandb=False),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "matryoshka_result = SyntheticSAERunner(matryoshka_cfg).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-header",
   "metadata": {},
   "source": [
    "### Standard L1 SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import StandardTrainingSAEConfig\n",
    "\n",
    "standard_cfg = SyntheticSAERunnerConfig(\n",
    "    synthetic_model=\"decoderesearch/synth-sae-bench-16k-v1\",\n",
    "    sae=StandardTrainingSAEConfig(\n",
    "        d_in=768,\n",
    "        d_sae=4096,\n",
    "        l1_coefficient=2.0,  # should result in L0 around 20-25\n",
    "        l1_warm_up_steps=10_000,\n",
    "    ),\n",
    "    training_samples=200_000_000,\n",
    "    batch_size=1024,\n",
    "    lr=3e-4,\n",
    "    eval_frequency=1000,\n",
    "    eval_samples=500_000,\n",
    "    autocast_sae=True,\n",
    "    autocast_data=True,\n",
    "    logger=LoggingConfig(log_to_wandb=False),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "standard_result = SyntheticSAERunner(standard_cfg).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "### Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    \"BatchTopK\": btk_result.final_eval,\n",
    "    \"Matryoshka BTK\": matryoshka_result.final_eval,\n",
    "    \"Standard L1\": standard_result.final_eval,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, ev in results.items():\n",
    "    assert ev is not None\n",
    "    rows.append(\n",
    "        {\n",
    "            \"Architecture\": name,\n",
    "            \"R\\u00b2\": f\"{ev.explained_variance:.4f}\",\n",
    "            \"MCC\": f\"{ev.mcc:.4f}\",\n",
    "            \"Uniqueness\": f\"{ev.uniqueness:.4f}\",\n",
    "            \"F1\": f\"{ev.classification.f1_score:.4f}\",\n",
    "            \"Precision\": f\"{ev.classification.precision:.4f}\",\n",
    "            \"Recall\": f\"{ev.classification.recall:.4f}\",\n",
    "            \"SAE L0\": f\"{ev.sae_l0:.1f}\",\n",
    "            \"Shrinkage\": f\"{ev.shrinkage:.4f}\",\n",
    "            \"Dead\": ev.dead_latents,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-discussion",
   "metadata": {},
   "source": [
    "Some patterns you may observe (consistent with the SynthSAEBench paper):\n",
    "\n",
    "- **Matryoshka SAEs** tend to have the best MCC and F1 (latent quality) despite lower explained variance (reconstruction)\n",
    "- **Standard L1 SAEs** suffer from shrinkage, where the SAE systematically reduces activation magnitudes\n",
    "- No architecture achieves perfect F1, reproducing the known gap between SAE probing and supervised probing seen in LLM SAE evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standalone-eval-header",
   "metadata": {},
   "source": [
    "## Standalone evaluation\n",
    "\n",
    "You can also evaluate any SAE against the synthetic model outside of the training runner using `eval_sae_on_synthetic_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standalone-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.synthetic import eval_sae_on_synthetic_data\n",
    "\n",
    "eval_result = eval_sae_on_synthetic_data(\n",
    "    sae=btk_result.sae,\n",
    "    feature_dict=model.feature_dict,\n",
    "    activations_generator=model.activation_generator,\n",
    "    num_samples=500_000,\n",
    "    batch_size=1024,\n",
    ")\n",
    "\n",
    "print(f\"MCC: {eval_result.mcc:.4f}\")\n",
    "print(f\"F1:  {eval_result.classification.f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-header",
   "metadata": {},
   "source": [
    "## Creating custom benchmark models\n",
    "\n",
    "You can create custom synthetic models for ablation studies. For example, to study the effect of superposition, vary the hidden dimension while keeping everything else fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.synthetic import (\n",
    "    SyntheticModelConfig,\n",
    "    ZipfianFiringProbabilityConfig,\n",
    "    OrthogonalizationConfig,\n",
    ")\n",
    "\n",
    "# A smaller, faster model for quick experiments\n",
    "small_cfg = SyntheticModelConfig(\n",
    "    num_features=1024,\n",
    "    hidden_dim=256,\n",
    "    firing_probability=ZipfianFiringProbabilityConfig(\n",
    "        exponent=0.5,\n",
    "        max_prob=0.4,\n",
    "        min_prob=5e-4,\n",
    "    ),\n",
    "    orthogonalization=OrthogonalizationConfig(num_steps=100, lr=3e-4),\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Train directly on a config (creates a temporary model)\n",
    "small_runner_cfg = SyntheticSAERunnerConfig(\n",
    "    synthetic_model=small_cfg,\n",
    "    sae=BatchTopKTrainingSAEConfig(\n",
    "        d_in=256,\n",
    "        d_sae=512,\n",
    "        k=10,\n",
    "    ),\n",
    "    training_samples=10_000_000,\n",
    "    batch_size=1024,\n",
    "    lr=3e-4,\n",
    "    logger=LoggingConfig(log_to_wandb=False),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "small_result = SyntheticSAERunner(small_runner_cfg).run()\n",
    "\n",
    "assert small_result.final_eval is not None\n",
    "print(f\"MCC: {small_result.final_eval.mcc:.4f}\")\n",
    "print(f\"F1:  {small_result.final_eval.classification.f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wandb-header",
   "metadata": {},
   "source": [
    "## Logging to Weights & Biases\n",
    "\n",
    "To enable wandb logging, pass a `LoggingConfig` with `log_to_wandb=True`. Training loss, evaluation metrics (MCC, F1, etc.), and other diagnostics will be logged automatically.\n",
    "\n",
    "```python\n",
    "from sae_lens import LoggingConfig\n",
    "\n",
    "runner_cfg = SyntheticSAERunnerConfig(\n",
    "    ...,\n",
    "    logger=LoggingConfig(\n",
    "        log_to_wandb=True,\n",
    "        wandb_project=\"synth-sae-bench\",\n",
    "        wandb_entity=\"my-team\",  # Optional\n",
    "        run_name=\"batchtopk-k25\",  # Auto-generated if not set\n",
    "        wandb_log_frequency=10,\n",
    "    ),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial we covered:\n",
    "\n",
    "1. **Loading SynthSAEBench-16k** and exploring its properties\n",
    "2. **Training SAEs** using `SyntheticSAERunner` with BatchTopK, Matryoshka, and Standard L1 architectures\n",
    "3. **Evaluating SAEs** with ground-truth metrics (MCC, F1, precision, recall, explained variance)\n",
    "4. **Comparing architectures** to understand their trade-offs\n",
    "5. **Creating custom models** for ablation studies\n",
    "\n",
    "### Next steps\n",
    "\n",
    "- Try other architectures: `JumpReLUTrainingSAEConfig`, `MatchingPursuitTrainingSAEConfig`\n",
    "- Sweep L0 values to observe the precision-recall trade-off\n",
    "- Create custom models with different hierarchy depths, correlation strengths, or superposition levels\n",
    "- See the [synthetic data docs](https://decoderesearch.github.io/SAELens/synthetic_data/) for the full API reference\n",
    "- See the [SynthSAEBench docs](https://decoderesearch.github.io/SAELens/synth_sae_bench/) for benchmark details and recommended settings\n",
    "- See the [SynthSAEBench paper](https://arxiv.org/abs/2602.14687) for more details on the synthetic data primitives and the benchmark results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
